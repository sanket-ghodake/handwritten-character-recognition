{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BE Project.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPRLpKPVpXNi96BjzYXTQ6Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanket-ghodake/handwritten-character-recognition/blob/main/BE_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries \n",
        "  RESTART RUNTIME if required"
      ],
      "metadata": {
        "id": "66VBb5rZnmQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install packages { display-mode: \"form\" }\n",
        "\n",
        "# Tesseract important links\n",
        "# https://github.com/madmaze/pytesseract\n",
        "# https://bhadreshpsavani.medium.com/how-to-use-tesseract-library-for-ocr-in-google-colab-notebook-5da5470e4fe0 \n",
        "# https://stackoverflow.com/questions/55319949/pil-typeerror-cannot-handle-this-data-type#:~:text=Additionally%2C%20please%20make%20sure%20the%20dtype%20is%20uint8(for%20gray)%20or%20bool(for%20binary). \n",
        "# https://github.com/tesseract-ocr/tesseract/blob/main/doc/tesseract.1.asc#config-files-and-augmenting-with-user-data \n",
        "# https://github.com/tesseract-ocr/tessdoc/blob/main/ImproveQuality.md \n",
        "# https://askubuntu.com/questions/793634/how-do-i-install-a-new-language-pack-for-tesseract-on-16-04 \n",
        "# https://stackoverflow.com/questions/44691829/pytesseract-foreign-language-extraction-using-python \n",
        "# https://tesseract-ocr.github.io/tessdoc/Data-Files-in-different-versions.html \n",
        "!pip install ipyplot\n",
        "# !sudo apt install tesseract-ocr-all # for all languages\n",
        "!sudo apt install tesseract-ocr # only end language\n",
        "!pip install pytesseract\n",
        "# RESTART runtime if warning shown\n",
        "! pip install Pillow==9.0.0 # https://stackoverflow.com/questions/71738218/module-pil-has-not-attribute-resampling#:~:text=0,a%20different%20verison. "
      ],
      "metadata": {
        "id": "-vF1sbGfr0qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import Libraries { vertical-output: true, display-mode: \"form\" }\n",
        "\n",
        "import cv2\n",
        "from time import sleep\n",
        "import shutil\n",
        "import os\n",
        "import random\n",
        "try:\n",
        " from PIL import Image\n",
        "except ImportError:\n",
        " import Image\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import time \n",
        "import ipyplot\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import layers # https://github.com/tensorflow/tensorflow/issues/26813"
      ],
      "metadata": {
        "id": "1aDIM72rqWRP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e15a7e45-f50f-4441-fc49-220a40cefa75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "        WARNING! Google Colab Environment detected!\n",
            "        You might encounter issues while running in Google Colab environment.\n",
            "        If images are not displaying properly please try setting `force_b64` param to `True`.\n",
            "        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Binary image\n",
        "Note: declare path for image \n"
      ],
      "metadata": {
        "id": "gRaJFw1snuPC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1h3Y5z0qLtp"
      },
      "outputs": [],
      "source": [
        "#@title Input image { vertical-output: true, display-mode: \"form\" }\n",
        "def threshold__img(img,threshold):\n",
        "  binary = np.where(img < threshold, 0, 255).astype(np.uint8) # threshold\n",
        "  return binary\n",
        "\n",
        "path = input(print(\"Enter path of image\"))\n",
        "img = cv2.imread(path,0)\n",
        "img = img.astype(np.uint8)\n",
        "cv2_imshow(img)\n",
        "plt.hist(img.ravel(),256,[0,256]); plt.title(\"Histogram of image\"); # change value accordingly"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Range for thresholding { vertical-output: true, display-mode: \"form\" }\n",
        "print(\"Input range for thresholding\")\n",
        "x,y = map(int,input().split())\n",
        "interval = (y-x)//10\n",
        "l = []\n",
        "p = []\n",
        "\n",
        "for i in range(x,y+1,interval):\n",
        "  temp = threshold__img(img,i)\n",
        "  l.append(temp.copy())\n",
        "  p.append(i)\n",
        "\n",
        "ipyplot.plot_images(l,p, img_width=300,force_b64=True)"
      ],
      "metadata": {
        "id": "4d-jX0yYuy9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Binary image { vertical-output: true, display-mode: \"form\" }\n",
        "\n",
        "kernel = np.ones((5,5), np.uint8)\n",
        " \n",
        "\n",
        "img_erosion = cv2.erode(img, kernel, iterations=1)\n",
        "img_dilation = cv2.dilate(img, kernel, iterations=1)\n",
        " \n",
        "# cv2_imshow(img)\n",
        "# cv2_imshow(img_erosion)\n",
        "# cv2_imshow(img_dilation)\n",
        "\n",
        "binary=threshold__img(img_erosion.copy(),int(input(print(\"Enter Threshold Value\"))))\n",
        "# cv2_imshow(binary)\n",
        "\n",
        "opening = cv2.morphologyEx(binary.copy(), cv2.MORPH_OPEN, kernel)\n",
        "closing = cv2.morphologyEx(opening.copy(), cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "# cv2_imshow(opening)\n",
        "# cv2_imshow(closing)\n",
        "\n",
        "binary=closing.copy()\n",
        "cv2_imshow(binary)\n"
      ],
      "metadata": {
        "id": "Z9v3bfOKwftu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tesseract \n",
        "To extract pages ,lines ,words"
      ],
      "metadata": {
        "id": "aOSIu_fG9Z2v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uy6SffneWZK0"
      },
      "outputs": [],
      "source": [
        "#@title Using pytesseract for line and word segmentation { vertical-output: true, display-mode: \"form\" }\n",
        "import pytesseract\n",
        "import shutil\n",
        "import os\n",
        "import random\n",
        "try:\n",
        " from PIL import Image\n",
        "except ImportError:\n",
        " import Image\n",
        "import ipyplot\n",
        "from pytesseract import Output\n",
        "import cv2\n",
        "from pytesseract.pytesseract import Output\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import time \n",
        "\n",
        "img_directory =None # To Undo work\n",
        "word_flag=line_flag=False#-\n",
        "line_images = []\n",
        "word_images = []\n",
        "level_wise_images = []\n",
        "line=[]#-\n",
        "word=[]#-\n",
        "LEVEL1 = PAGE = 1\n",
        "LEVEL2 = BLOCK = 2 \n",
        "LEVEL3 = PARAGRAPH =3\n",
        "LEVEL4 = LINE = 4\n",
        "LEVEL5 = WORD = 5\n",
        "\n",
        "\n",
        "\n",
        "def psm_string(value):\n",
        "  '''\n",
        "  0    Orientation and script detection (OSD) only.\n",
        "  1    Automatic page segmentation with OSD.\n",
        "  2    Automatic page segmentation, but no OSD, or OCR.\n",
        "  3    Fully automatic page segmentation, but no OSD. (Default)\n",
        "  4    Assume a single column of text of variable sizes.\n",
        "  5    Assume a single uniform block of vertically aligned text.\n",
        "  6    Assume a single uniform block of text.\n",
        "  7    Treat the image as a single text line.\n",
        "  8    Treat the image as a single word.\n",
        "  9    Treat the image as a single word in a circle.\n",
        " 10    Treat the image as a single character.\n",
        " 11    Sparse text. Find as much text as possible in no particular order.\n",
        " 12    Sparse text with OSD.\n",
        " 13    Raw line. Treat the image as a single text line,\n",
        "\t\t\tbypassing hacks that are Tesseract-specific.\n",
        "  '''\n",
        "  return str('--psm '+str(value))\n",
        "\n",
        "def threshold_img(img,threshold =None):\n",
        "  plt.hist(img.ravel(),256,[0,256]); plt.show() # change value accordingly\n",
        "  if threshold is None:\n",
        "    print(\"Enter threshold value:\")\n",
        "    threshold = int(input())\n",
        "  binary = np.where(img < threshold, 0, 255) # threshold\n",
        "  return binary\n",
        "\n",
        "def indices_of_level(d):\n",
        "  '''\n",
        "  Level 1 Page\n",
        "  Level 2 Block\n",
        "  Level 3 Paragraph\n",
        "  Level 4 Line\n",
        "  Level 5 Word\n",
        "  '''\n",
        "  level ={} # dictionary for separating page,para,words.\n",
        "  for i in range(1,6):\n",
        "    # https://stackoverflow.com/questions/6294179/how-to-find-all-occurrences-of-an-element-in-a-list#:~:text=indices%20%3D%20%5Bi%20for%20i%2C%20x%20in%20enumerate(my_list)%20if%20x%20%3D%3D%20%22whatever%22%5D \n",
        "    indices = [j for j, x in enumerate(d['level']) if x == i ]\n",
        "    # print(i,\":\",indices,len(indices)) #-\n",
        "    level[i]=indices\n",
        "  return level\n",
        "\n",
        "def cropped_image_to_data(img,d,labels,level_indices=None):\n",
        "  cropped =[]\n",
        "  hh,ww = img.shape\n",
        "  for i in range(len(d['level'])):\n",
        "    # https://stackoverflow.com/questions/60869306/how-to-simple-crop-the-bounding-box-in-python-opencv#:~:text=cropped_image%20%3D%20img%5BY%3AY%2BH%2C%20X%3AX%2BW%5D%0Aprint(%5BX%2CY%2CW%2CH%5D)%0Aplt.imshow(cropped_image)%0Acv2.imwrite(%27contour1.png%27%2C%20cropped_image)\n",
        "    (x, y, w, h) = (d['left'][i], d['top'][i], d['width'][i], d['height'][i])\n",
        "    cropped_image = img[max(y-5,0):min(hh,y+h+5), max(x-5,0):min(x+w+5,ww)] # Added this line but tesseract accuracy decreases\n",
        "    # cropped_image = img[y:y+h, x:x+w] # original line\n",
        "    # print(labels[i])#-\n",
        "    temp = labels[i].split(\"\\n\")\n",
        "    # for i in temp[:-1]:#-\n",
        "      # print(i)\n",
        "    \n",
        "    # cv2_imshow(cropped_image)\n",
        "    # print()\n",
        "    cropped.append(cropped_image)\n",
        "    # print([x,y,w,h])\n",
        "\n",
        "  return cropped\n",
        "\n",
        "def labels_image_to_data(d):\n",
        "  labels =[]\n",
        "  for i in range(len(d['level'])):\n",
        "    temp=[]\n",
        "    for j in d:\n",
        "      # print(j,d[j][i],end=\" \")\n",
        "      s1=str(j)\n",
        "      s2=str(d[j][i])\n",
        "      # https://stackoverflow.com/questions/35236759/printing-string-with-two-columns#:~:text=%27%7B0%3A10%7D%20%20%7B1%7D%27.format(s1%2C%20s2)\n",
        "      temp.append('{0:15}  {1}'.format(s1, s2))\n",
        "      \n",
        "    labels.append('\\n'.join(temp))\n",
        "  return labels\n",
        "\n",
        "def draw_boxes(img,d,level=0):\n",
        "  name = ['PAGE','BLOCK','PARAGRAPH','LINE','WORD']\n",
        "  # Not important below for loop\n",
        "  n_boxes = len(d['level'])\n",
        "  image = img.copy() # can change to binary.copy()\n",
        "  for i in range(n_boxes):\n",
        "    '''\n",
        "    x1,y1 ------\n",
        "    |          |\n",
        "    |          |\n",
        "    |          |\n",
        "    --------x2,y2\n",
        "    '''\n",
        "    if d['level'][i]!=level:\n",
        "      continue\n",
        "    (x, y, w, h) = (d['left'][i], d['top'][i], d['width'][i], d['height'][i])\n",
        "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "  # print()\n",
        "  # if level==0:\n",
        "  #   print(\"All bounding boxes\")\n",
        "  # else: \n",
        "  #   print(\"Level\",level,\"bounding boxes (\",name[level-1],\")\")\n",
        "  # cv2_imshow(image)\n",
        "  return image.copy()\n",
        "\n",
        "def save_levewise_images_into_direcotry(img,d,level_indices,cropped,parent_directory=None,level=0,labels=None):#-\n",
        "  root = '/content/' # for google colab\n",
        "  parent_directory = None\n",
        "\n",
        "  # Making directory if not exists\n",
        "  if parent_directory is None :\n",
        "    try:\n",
        "      parent_directory =str(os.getcwd())\n",
        "    except:\n",
        "      parent_directory = root\n",
        "  elif not os.path.isdir(parent_directory):\n",
        "    print('No directory exists')\n",
        "    os.makedirs(parent_directory) # Not tested this line \n",
        "  try:\n",
        "    # Make directory to store images if not exist\n",
        "    directory = os.path.join(parent_directory,'tesseract after processing')\n",
        "    if not os.path.exists(directory):\n",
        "      os.makedirs(directory)\n",
        "    os.chdir(directory)\n",
        "\n",
        "    # Making directory with date\n",
        "    directory = os.path.join(directory,time.strftime(\"%Y-%m-%d\"))\n",
        "    if not os.path.exists(directory):\n",
        "      os.makedirs(directory)\n",
        "    os.chdir(directory)\n",
        "\n",
        "    # Making directory for current image\n",
        "    if len(os.listdir(directory)) == 0:\n",
        "      directory = os.path.join(directory,str(1).zfill(3))\n",
        "    else: # TO DO: I think this can handle folder upto 100 only then throws error\n",
        "      all_folders = os.listdir(directory)\n",
        "      all_folders= list(map(int, all_folders))\n",
        "      all_folders.sort()\n",
        "      latest = all_folders[-1]\n",
        "      new = int(latest) + 1\n",
        "      directory = os.path.join(directory,str(new).zfill(3))\n",
        "    os.makedirs(directory)\n",
        "    os.chdir(directory)\n",
        "\n",
        "    global img_directory\n",
        "    img_directory = directory # Saving for checkpoint\n",
        "    # Storing original image\n",
        "    # original = cv2.imread(\"/content/1.jpeg\",0)\n",
        "    original = img.copy()\n",
        "    cv2.imwrite('original_image.png',original) \n",
        "    # TO DO - If have multiple pages or PDF saving all pages or PDF\n",
        "\n",
        "\n",
        "    if level ==0: # save all level images in tree shape\n",
        "      # Storing end point of total levels\n",
        "      end = len(d['level'])\n",
        "      # print(\"Total of levels:\",end)\n",
        "      # print()\n",
        "\n",
        "      # Saving all levels data in tree structure\n",
        "      words =[]\n",
        "      w = len(level_indices[5])\n",
        "      lines =[]\n",
        "      l = len(level_indices[4])\n",
        "      paragraphs =[]\n",
        "      p =len(level_indices[3])\n",
        "      blocks =[]\n",
        "      b =len(level_indices[2])\n",
        "      pages =[]\n",
        "      pg = len(level_indices[1])\n",
        "\n",
        "      for i in range(end-1,-1,-1):\n",
        "        # print(i)\n",
        "        if i in level_indices[5]:\n",
        "          words.append((w,i))\n",
        "          w-=1\n",
        "        elif i in level_indices[4]:\n",
        "          lines.append((l,i,words))\n",
        "          l-=1\n",
        "          words = []\n",
        "        elif i in level_indices[3]:\n",
        "          paragraphs.append((p,i,lines))\n",
        "          p-=1\n",
        "          lines =[]\n",
        "        elif i in level_indices[2]:\n",
        "          blocks.append((b,i,paragraphs))\n",
        "          b-=1\n",
        "          paragraphs =[]\n",
        "        elif i in level_indices[1]:\n",
        "          pages.append((pg,i,blocks))\n",
        "          pg-=1\n",
        "          blocks =[]\n",
        "\n",
        "      # Extracting tree structure\n",
        "      for i in pages:\n",
        "        # Creating folder for pages \n",
        "        # Not tested for multiple pages\n",
        "        page_directory = os.path.join(directory,str(\"Page No:\"+str(i[0]))) \n",
        "        if not os.path.exists(page_directory):\n",
        "          os.makedirs(page_directory)\n",
        "        os.chdir(page_directory)\n",
        "\n",
        "        cv2.imwrite(str(\"Page No:\"+str(i[0])+\".jpg\"),cropped[i[1]])\n",
        "        # print(\"Page No:\",i[0],\"index at\",i[1],\"total blocks\",len(i[2]))\n",
        "        for j in i[2]:\n",
        "          block_directory = os.path.join(page_directory,str(\"Block No:\"+str(j[0])))\n",
        "          if not os.path.exists(block_directory):\n",
        "            os.makedirs(block_directory)\n",
        "          os.chdir(block_directory)\n",
        "\n",
        "          cv2.imwrite(str(\"Block No:\"+str(j[0])+\".jpg\"),cropped[j[1]])\n",
        "          # print(\"\\tBlock No:\",j[0],\"index at\",j[1],\"total paragraphs\",len(j[2]))\n",
        "          for k in j[2]:\n",
        "            paragraph_directory = os.path.join(block_directory,str(\"Paragraph No:\"+str(k[0])))\n",
        "            if not os.path.exists(paragraph_directory):\n",
        "              os.makedirs(paragraph_directory)\n",
        "            os.chdir(paragraph_directory)\n",
        "\n",
        "            cv2.imwrite(str(\"Paragraph No:\"+str(k[0])+\".jpg\"),cropped[k[1]])\n",
        "            # print(\"\\t\\tParagraph No:\",k[0],\"index at\",k[1],\"total lines\",len(k[2]))\n",
        "            for l in k[2]: \n",
        "              line_directory = os.path.join(paragraph_directory,str(\"Line No:\"+str(l[0])))\n",
        "              if not os.path.exists(line_directory):\n",
        "                os.makedirs(line_directory)\n",
        "              os.chdir(line_directory)\n",
        "\n",
        "              cv2.imwrite(str(\"Line No:\"+str(l[0])+\".jpg\"),cropped[l[1]])\n",
        "              # print(\"\\t\\t\\tLine No:\",l[0],\"index at\",l[1],\"total words\",len(l[2]))\n",
        "              for m in l[2]:\n",
        "                word_directory = os.path.join(line_directory,str(\"Word No:\"+str(m[0])))\n",
        "                if not os.path.exists(word_directory):\n",
        "                  os.makedirs(word_directory)\n",
        "                os.chdir(word_directory)\n",
        "\n",
        "                # print(\"\\t\\t\\t\\t\",\"Word No\",m[0],\"index at\",l[1])   \n",
        "                cv2.imwrite(str(\"Word No:\"+str(m[0])+\".jpg\"),cropped[m[1]])  \n",
        "        \n",
        "      os.chdir(parent_directory)\n",
        "\n",
        "    else: # save only that level images\n",
        "      # creating directory for level\n",
        "      name = [\"Page\",\"Block\",\"Paragraph\",\"Line\",\"Word\"]\n",
        "      level_directory = os.path.join(directory,str(name[level-1]+\" level only\"))\n",
        "      # print(\"Saving\",name[level-1],\"level only\") \n",
        "      if not os.path.exists(level_directory):\n",
        "        os.makedirs(level_directory)\n",
        "      os.chdir(level_directory)\n",
        "\n",
        "      count =0\n",
        "      global level_wise_images\n",
        "      global word\n",
        "      for i in range(len(d['level'])):\n",
        "        if d['level'][i]==level:\n",
        "          count+=1\n",
        "          # print(\"\\t\",name[level-1], \"No:\",count,\"index at\",i)   \n",
        "          cv2.imwrite(str(name[level-1]+\" No:\"+str(count).zfill(2)+\".jpg\"),cropped[i])\n",
        "          level_wise_images.append(cropped[i].copy())\n",
        "          #-\n",
        "          if word_flag:#-\n",
        "            word.append(d['text'][i])\n",
        "            # print(d['text'][i])\n",
        "          #-\n",
        "\n",
        "      os.chdir(parent_directory)\n",
        "\n",
        "  except:\n",
        "    os.chdir(parent_directory)\n",
        "    print(\"Error Occurs while making directory\")\n",
        "\n",
        "def tesseract(path= None,img= None,psm = 3,image_to_boxes=False,threshold =True,level =0,directory=None,resize_dilation =False):\n",
        "  if (path is None or path ==\"\") and img is None:\n",
        "    return 0\n",
        "  try:\n",
        "    global level_wise_images\n",
        "    level_wise_images.clear() # clear list\n",
        "\n",
        "    # preprocessing\n",
        "    if path:\n",
        "      original = cv2.imread(path,0)\n",
        "    elif img is not None:\n",
        "      original = img.copy()\n",
        "\n",
        "    if threshold:\n",
        "      binary = threshold_img(original.copy())\n",
        "      binary = np.array(binary,dtype=np.uint8)\n",
        "    else :\n",
        "      binary = original.copy()\n",
        "      binary = np.array(binary,dtype=np.uint8)\n",
        "\n",
        "    # resize # can be removed\n",
        "    if resize_dilation:\n",
        "      kernel = np.zeros((3,3),np.uint8)\n",
        "      dilation = cv2.dilate(255-binary,kernel,iterations = 15)\n",
        "      binary = cv2.resize(255-dilation, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC) \n",
        "      original = cv2.resize(original, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC) \n",
        "\n",
        "    # print(\"Original Image,Binary Image\")\n",
        "    # print(\"dtype:\",original.dtype,binary.dtype)\n",
        "    # print(\"shape:\",original.shape,binary.shape)\n",
        "\n",
        "    # For pytesseract input - https://stackoverflow.com/questions/55319949/pil-typeerror-cannot-handle-this-data-type#:~:text=Additionally%2C%20please%20make%20sure%20the%20dtype%20is%20uint8(for%20gray)%20or%20bool(for%20binary).\n",
        "    # print()\n",
        "    # print(\"For tesseract to work dtype of image should be 'unit8'\")\n",
        "    \n",
        "    # tesseract\n",
        "    original_ =original.copy()\n",
        "    binary_ = binary.copy()\n",
        "    # https://stackoverflow.com/questions/20831612/getting-the-bounding-box-of-the-recognized-words-using-python-tesseract#:~:text=Use%20pytesseract.image_to_data()\n",
        "    if not image_to_boxes:\n",
        "       # https://stackoverflow.com/questions/44619077/pytesseract-ocr-multiple-config-options#:~:text=tesseract%2D4.0.0a%20supports%20below%20psm.%20If%20you%20want%20to%20have%20single%20character%20recognition%2C%20set%20psm%20%3D%2010\n",
        "      try:\n",
        "        d = pytesseract.image_to_data(binary_,output_type=Output.DICT,config=str(\"-c tessedit_char_whitelist=0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz \"+psm_string(psm)))\n",
        "      except Exception as e:\n",
        "        print(\"Error occureed in 'if not image_to_boxes:' block:\",e)\n",
        "    else:\n",
        "      d = pytesseract.image_to_boxes(binary_,output_type=Output.DICT,config=str(\"-c tessedit_char_whitelist=0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz \"+psm_string(psm)))#-\n",
        "    # print()\n",
        "    # print(\"image_to_data dictionary:\")\n",
        "    for j,i in enumerate(d):#-\n",
        "      if j <(len(d)-1):#-\n",
        "        # print(\"\\t\",i,d[i],len(d[i]))\n",
        "        pass\n",
        "\n",
        "    if level ==0:\n",
        "      for i in range(1,6):\n",
        "        draw_boxes(original_.copy(),d,level=i)\n",
        "    else:\n",
        "      draw_boxes(original.copy(),d,level=level)\n",
        "    \n",
        "    # print()\n",
        "    labels =labels_image_to_data(d)\n",
        "    level_indices = indices_of_level(d)\n",
        "    cropped=cropped_image_to_data(binary.copy(),d,labels,level_indices=level_indices) # Send appropriate image to function\n",
        "    save_levewise_images_into_direcotry(img =original.copy(),d=d,level_indices=level_indices,cropped=cropped,parent_directory=None,level=level,labels=labels)#-\n",
        "    # ipyplot.plot_images(cropped,labels=labels1,max_images=80,force_b64=True,img_width=200) \n",
        "\n",
        "    return original,binary,original_,binary_,labels,cropped,d\n",
        "  except:\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Page to lines "
      ],
      "metadata": {
        "id": "cZbKlmtY944I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Page to lines { vertical-output: true, display-mode: \"form\" }\n",
        "# for line images\n",
        "\n",
        "def pages_to_lines(img):\n",
        "  global level_wise_images,line_images\n",
        "  line_images.clear()\n",
        "  line_flag=True #-\n",
        "  word_flag=False #-\n",
        "  tesseract(img=img,threshold=False,psm =12,level=LINE)\n",
        "  line_images = level_wise_images.copy()\n",
        "  level_wise_images.clear()"
      ],
      "metadata": {
        "id": "VMvTiUfbAiLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Line to words"
      ],
      "metadata": {
        "id": "9IRm4-Ix7UBb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLBQXRuA7pnl"
      },
      "outputs": [],
      "source": [
        "#@title Line to Words function { vertical-output: true, display-mode: \"form\" }\n",
        "# for word images\n",
        "def line_to_words(img):\n",
        "  global level_wise_images,line_images,word_images\n",
        "  line_flag =False#-\n",
        "  word_images.clear()\n",
        "  word_flag=True #-\n",
        "  for i in line_images: # lines\n",
        "    level_wise_images.clear()\n",
        "    tesseract(img=img,psm =7,threshold =False,level=WORD)\n",
        "    word_images.append(level_wise_images.copy())\n",
        "  level_wise_images.clear()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word to characters"
      ],
      "metadata": {
        "id": "bGGyzXl5oT1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Word to Characters function { vertical-output: true, display-mode: \"form\" }\n",
        "from skimage.filters import threshold_otsu\n",
        "\n",
        "def word_to_characeters(img):\n",
        "  #binarize the image, guassian blur will remove any noise in the image\n",
        "  first_line = img.copy()\n",
        "\n",
        "  # first_line = 255 -first_line\n",
        "  thresh = threshold_otsu(first_line)\n",
        "  binary = first_line > thresh\n",
        "  # print(thresh)\n",
        "\n",
        "  # find the vertical projection by adding up the values of all pixels along rows\n",
        "  vertical_projection = np.sum(binary, axis=0)\n",
        "\n",
        "  # plot the vertical projects\n",
        "  # fig, ax = plt.subplots(nrows=2, figsize=(20,10))\n",
        "  # plt.xlim(0, first_line.shape[1])\n",
        "  # ax[0].imshow(binary, cmap=\"gray\")\n",
        "  # ax[1].plot(vertical_projection)\n",
        "\n",
        "  height = first_line.shape[0]\n",
        "\n",
        "  ## we will go through the vertical projections and \n",
        "  ## find the sequence of consecutive white spaces in the image\n",
        "  whitespace_lengths = []\n",
        "  whitespace = 0\n",
        "  index = 0\n",
        "  index_=[]\n",
        "  for vp in vertical_projection:\n",
        "      \n",
        "      if vp == height:\n",
        "          whitespace = whitespace + 1\n",
        "      elif vp != height:\n",
        "          if whitespace != 0:\n",
        "              whitespace_lengths.append(whitespace)\n",
        "              index_.append(index)\n",
        "          whitespace = 0 # reset whitepsace counter. \n",
        "      index+=1\n",
        "  # print(\"whitespaces:\", whitespace_lengths)\n",
        "  avg_white_space_length = np.mean(whitespace_lengths)\n",
        "  # print(\"average whitespace lenght:\", avg_white_space_length)\n",
        "\n",
        "  # plt.imshow(binary,cmap='gray')\n",
        "  # for xc in index_:\n",
        "  #     plt.axvline(x=xc)\n",
        "\n",
        "  ## find index of whitespaces which are actually long spaces using the avg_white_space_length\n",
        "  whitespace_length = 0\n",
        "  divider_indexes = []\n",
        "  for index, vp in enumerate(vertical_projection):\n",
        "      if vp == height:\n",
        "          whitespace_length = whitespace_length + 1\n",
        "      elif vp != height:\n",
        "          if whitespace_length != 0 or whitespace_length > (avg_white_space_length):#change here\n",
        "              divider_indexes.append(index-int(whitespace_length/2))\n",
        "              whitespace_length = 0 # reset it\n",
        "            \n",
        "\n",
        "\n",
        "  for index, vp in reversed(list(enumerate(vertical_projection))):# for last word segmentation\n",
        "      if vp == height:\n",
        "          whitespace_length = whitespace_length + 1\n",
        "      elif vp != height:\n",
        "          if whitespace_length != 0 or whitespace_length > (avg_white_space_length):\n",
        "              divider_indexes.append(index+int(whitespace_length/2))\n",
        "              break\n",
        "              whitespace_length = 0 # reset it\n",
        "    \n",
        "  # print(divider_indexes)\n",
        "\n",
        "  # plt.imshow(binary,cmap='gray')\n",
        "  # for xc in divider_indexes:\n",
        "  #     plt.axvline(x=xc)\n",
        "\n",
        "  # lets create the block of words from divider_indexes\n",
        "  divider_indexes = np.array(divider_indexes)\n",
        "  dividers = np.column_stack((divider_indexes[:-1],divider_indexes[1:]))\n",
        "  # fig, ax = plt.subplots(nrows=len(dividers), figsize=(5,10))\n",
        "  l=[]\n",
        "  for index, window in enumerate(dividers):\n",
        "      # ax[index].axis(\"off\")\n",
        "      # ax[index].imshow(first_line[:,window[0]:window[1]], cmap=\"gray\")\n",
        "      # cv2_imshow(first_line[:,window[0]:window[1]])\n",
        "      l.append(first_line[:,window[0]:window[1]])\n",
        "  return l\n"
      ],
      "metadata": {
        "id": "ZgO9b4OyogVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing for characters"
      ],
      "metadata": {
        "id": "yA2PRo8A9T9B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKuftKo7454w"
      },
      "outputs": [],
      "source": [
        "#@title Character image preprocessing { vertical-output: true, display-mode: \"code\" }\n",
        "def vertical_projection_plt(img): # TODO: Not supporting multiple plots. Can use for single image at a time as a testing purpose\n",
        "  # img - binary img\n",
        "  from skimage.filters import threshold_otsu\n",
        "  #binarize the image, guassian blur will remove any noise in the image\n",
        "  # find the vertical projection by adding up the values of all pixels along rows\n",
        "  vertical_projection = np.sum(img, axis=0)\n",
        "  # plot the vertical projects\n",
        "  fig, ax = plt.subplots(nrows=2, figsize=(10,5))\n",
        "  plt.xlim(0, img.shape[1])\n",
        "  ax[0].imshow(img, cmap=\"gray\")\n",
        "  ax[1].plot(vertical_projection)\n",
        "\n",
        "def crop_image_remove_white(gray, pixel_value=255):\n",
        "    # gray = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # OTSU threshold lines are added by me.\n",
        "    (thresh, im_bw) = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "    gray = cv2.threshold(gray, thresh, 255, cv2.THRESH_BINARY)[1]\n",
        "\n",
        "    crop_rows = gray[~np.all(gray == pixel_value, axis=1), :]\n",
        "    cropped_image = crop_rows[:, ~np.all(crop_rows == pixel_value, axis=0)]\n",
        "    # cv2_imshow(cropped_image)\n",
        "    # print(cropped_image.shape)\n",
        "    return cropped_image\n",
        "\n",
        "def overlay_image_centre(img):\n",
        "  # blank padding for words\n",
        "  # grayscale image \n",
        "  h, w = img.shape\n",
        "  # print(h,w)\n",
        "\n",
        "  # square_side = max(h,w)+10\n",
        "  hh = h+120\n",
        "  ww = w+100\n",
        "\n",
        "  # load background image as white\n",
        "  back = np.full((hh,ww),255,np.uint8)\n",
        "  hh, ww = back.shape\n",
        "  # print(hh,ww)\n",
        "\n",
        "  # compute xoff and yoff for placement of upper left corner of resized image   \n",
        "  yoff = round((hh-h)/2)\n",
        "  xoff = round((ww-w)/2)\n",
        "  # print(yoff,xoff)\n",
        "\n",
        "  # use numpy indexing to place the resized image in the center of background image\n",
        "  result = back.copy()\n",
        "  result[yoff:yoff+h, xoff:xoff+w] = img\n",
        "\n",
        "  # view result\n",
        "  # cv2_imshow(result)\n",
        "  return result \n",
        "\n",
        "def character_preprocessing(i):\n",
        "  img = i.copy()\n",
        "  # resize \n",
        "  img = cv2.resize(img, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
        "  # otsu threshold\n",
        "  (thresh, im_bw) = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY and cv2.THRESH_OTSU)\n",
        "  gray = cv2.threshold(img, thresh, 255, cv2.THRESH_BINARY)[1]\n",
        "  # cv2_imshow(gray)\n",
        "\n",
        "  #padding\n",
        "  gray = crop_image_remove_white(gray)\n",
        "  padding = overlay_image_centre(gray)\n",
        "  kernel = np.ones((5,5), np.uint8)\n",
        " \n",
        "  padding = cv2.erode(padding, kernel, iterations=1)\n",
        "  # blur and dilation / inverting img for blur and dilation \n",
        "  # kernel = np.zeros((3,3),np.uint8)\n",
        "  # blur = cv2.bilateralFilter(255-padding,9,75,75)\n",
        "  # median = cv2.medianBlur(255-padding,5)\n",
        "  # dilation = cv2.dilate(median,kernel,iterations = 10)\n",
        "  # cv2_imshow(255-dilation)\n",
        "\n",
        "  # padding again\n",
        "  # padding = overlay_image_centre(255-dilation)\n",
        "  # print(\"Shape of word after processing\",padding.shape)\n",
        "  \n",
        "  # cv2_imshow(cv2.resize(padding, None, fx=0.2, fy=0.2, interpolation=cv2.INTER_CUBIC))\n",
        "  return padding.copy()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Character recongintion \n",
        "Note: Select Model \n",
        "  1. alphanumeric merged #default\n",
        "  2. Capital Letters\n",
        "  3. Digits\n",
        "  4. Letters \n",
        "  5. Digits+Capital Letters\n",
        "  6. Small Letters\n",
        "\n",
        "Binary model means that it trained on binary images while other models are trained on grayscale images."
      ],
      "metadata": {
        "id": "y0IaR3ILzGGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Pre-trained Models { vertical-output: true, display-mode: \"form\" }\n",
        "# https://stackoverflow.com/questions/65099766/is-there-a-way-to-download-data-from-a-public-link-to-google-colab \n",
        "!gdown --id 14MSJCQIh457Cd4uPR395zZp7YSE5km2B # https://drive.google.com/file/d/14MSJCQIh457Cd4uPR395zZp7YSE5km2B/view?usp=sharing Digits only MNIST\n",
        "!gdown --id 1o85fvoQFbruEYxThxYSQTUrNaMPKFaII # https://drive.google.com/file/d/1o85fvoQFbruEYxThxYSQTUrNaMPKFaII/view?usp=sharing Capital Letters only EMNIST\n",
        "!gdown --id 1xM7LnSTLThRMGqzF_3_ZlnhSg1iqSBkg # https://drive.google.com/file/d/1xM7LnSTLThRMGqzF_3_ZlnhSg1iqSBkg/view?usp=sharing EMNIST Bymerge\n",
        "!gdown --id 1iDIyUZKFWXFVKqobEm3nXcSsAkzSbQab # https://drive.google.com/file/d/1iDIyUZKFWXFVKqobEm3nXcSsAkzSbQab/view?usp=sharing EMNIST Bymerge 47 classes Augmented binary\n",
        "!gdown --id 1M6MbQw9Ge5iBY8MNxwM3iYwaGWzBpIxj # https://drive.google.com/file/d/1M6MbQw9Ge5iBY8MNxwM3iYwaGWzBpIxj/view?usp=sharing MNIST Binary\n",
        "!gdown --id 1mXadeBLXSKmT83qUA40Tn-Egvin93atC # https://drive.google.com/file/d/1mXadeBLXSKmT83qUA40Tn-Egvin93atC/view?usp=sharing EMNIST letters small capital bymerge binary loss 0.4683 - accuracy 0.8583\n",
        "!gdown --id 1s9thtIKgjUdL0vw9sK58q1UtnlefWaEO # https://drive.google.com/file/d/1s9thtIKgjUdL0vw9sK58q1UtnlefWaEO/view?usp=sharing EMNIST letters small capital Augmented binary loss 0.3429 - accuracy 0.9061\n"
      ],
      "metadata": {
        "id": "xlBKjpSA3WNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Predict output from model { vertical-output: true, display-mode: \"form\" }\n",
        "new_model = None\n",
        "choice = None\n",
        "def model_choice(model=1):\n",
        "  global new_model,choice,binary_model\n",
        "  choice=model\n",
        "  if model == 1:\n",
        "    if binary_model:\n",
        "      new_model = tf.keras.models.load_model('/content/EMNIST 47 classes Augmented binary loss 0.4645 - accuracy 0.8708.h5')\n",
        "    else:\n",
        "      new_model = tf.keras.models.load_model('/content/emnist bymerge.h5')\n",
        "  elif model == 2:\n",
        "    new_model = tf.keras.models.load_model('/content/capital_letters.h5')\n",
        "  elif model == 3:\n",
        "    if binary_model:\n",
        "      new_model = tf.keras.models.load_model('/content/mnist binary loss 0.0843 - accuracy 0.9745.h5')\n",
        "    else:\n",
        "      new_model = tf.keras.models.load_model('/content/Copy of model 0.9826 mnist.h5')\n",
        "  elif model == 4:\n",
        "    # new_model = tf.keras.models.load_model('/content/EMNIST letters small capital Augmented binary loss 0.3429 - accuracy 0.9061.h5')\n",
        "    new_model = tf.keras.models.load_model('/content/letters small capital bymerge binary loss 0.4683 - accuracy 0.8583.h5')\n",
        "    \n",
        "    \n",
        "\n",
        "def predict(character,model=1):\n",
        "  global new_model\n",
        "  character = character_preprocessing(character)\n",
        "  alphanumeric_merge_dict = {'0': '0', '1': '1', '2': '2', '3': '3', '4': '4', '5': '5', '6': '6', '7': '7', '8': '8', '9': '9', '10': 'A', '11': 'B', '12': 'C', '13': 'D', '14': 'E', '15': 'F', '16': 'G', '17': 'H', '18': 'I', '19': 'J', '20': 'K', '21': 'L', '22': 'M', '23': 'N', '24': 'O', '25': 'P', '26': 'Q', '27': 'R', '28': 'S', '29': 'T', '30': 'U', '31': 'V', '32': 'W', '33': 'X', '34': 'Y', '35': 'Z', '36': 'a', '37': 'b', '38': 'd', '39': 'e', '40': 'f', '41': 'g', '42': 'h', '43': 'n', '44': 'q', '45': 'r', '46': 't'}\n",
        "  img = character.copy()\n",
        "  img = cv2.resize(img,(28,28))\n",
        "\n",
        "  img=255-img\n",
        "  img_final =np.reshape(img, (1,28,28,1))\n",
        "  m=new_model.predict([img_final])\n",
        "  t=np.argmax(m[0])\n",
        "\n",
        "  # cv2_imshow(character)\n",
        "  # cv2_imshow(img)\n",
        "  print(alphanumeric_merge_dict[str(t)],end=\"\")\n",
        "\n",
        "  return alphanumeric_merge_dict[str(t)]"
      ],
      "metadata": {
        "id": "hBf4OoyRzFSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HCR"
      ],
      "metadata": {
        "id": "UqGfPytm4eJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title HCR Project Output { vertical-output: true, display-mode: \"form\" }\n",
        "character_images = []\n",
        "def segmentation(binary):\n",
        "  global character_images\n",
        "  character_images.clear()\n",
        "  temp = []\n",
        "  pages_to_lines(binary.copy())\n",
        "  line_to_words(binary.copy())\n",
        "  for n,i in enumerate(word_images):\n",
        "    # word_preprocessing(i)\n",
        "    temp.clear()\n",
        "    for m,j in enumerate(i):\n",
        "      # print(\"Line\",n,\"Word\",m)\n",
        "\n",
        "      characters = word_to_characeters(j.copy())\n",
        "      # cv2_imshow(j)\n",
        "      temp.append(characters)\n",
        "    character_images.append(temp.copy())\n",
        "out = \"\"\"Select Model:\n",
        "\n",
        "1. Alphanumeric Merged #Default\n",
        "2. Capital Letters\n",
        "3. Digits\n",
        "4. Letters\n",
        "5. Digits+Capital Letters\n",
        "6. Small Letters\"\"\"\n",
        "binary_model=bool(input(print(\"Binary Model 1/0\")))\n",
        "\n",
        "model_choice(model=int(input(print(out))))\n",
        "cv2_imshow(cv2.resize(img, None, fx=0.2, fy=0.2, interpolation=cv2.INTER_CUBIC))\n",
        "cv2_imshow(cv2.resize(binary, None, fx=0.2, fy=0.2, interpolation=cv2.INTER_CUBIC))\n",
        "\n",
        "segmentation(binary.copy())\n",
        "output=\"\"\n",
        "print(\"Predicted Output:\",end=\" \")\n",
        "for n,i in enumerate(character_images):\n",
        "  for m,j in enumerate(i):\n",
        "    for l,k in enumerate(j):\n",
        "      i = k.copy()\n",
        "      try:\n",
        "        output+=predict(i)\n",
        "      except :\n",
        "        pass\n",
        "      finally:\n",
        "        pass\n",
        "    print(end=\" \")\n",
        "    output+=\" \"\n",
        "  print()\n",
        "  output+=\"\\n\"\n",
        "\n",
        "print(\"Output small letters:\",output.lower())"
      ],
      "metadata": {
        "id": "pNfWxCSECaPZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
