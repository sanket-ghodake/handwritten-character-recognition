{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "input_pipeline_for_dataset_images.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMHmUPrvcQDfPBz2lqGfviF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanket-ghodake/handwritten-character-recognition/blob/main/colab_notebooks/input_pipeline_for_dataset_images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "remove directory completely"
      ],
      "metadata": {
        "id": "3h-ip-XaW2MM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%rm -rf '/content/dataset'"
      ],
      "metadata": {
        "id": "xw8riEqX1Mox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "unzip file"
      ],
      "metadata": {
        "id": "IdUyItLEXJoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/dataset.zip\""
      ],
      "metadata": {
        "id": "OUERcq_LVp_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "import"
      ],
      "metadata": {
        "id": "9BCkQEFMXMFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "! pip install ipyplot\n",
        "import ipyplot\n",
        "import glob\n",
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "AGBGpUVo8a-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "functions"
      ],
      "metadata": {
        "id": "G25qOdvBXWNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_image_remove_white(gray, pixel_value=255):\n",
        "    # gray = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
        "    \n",
        "    # STEP 1\n",
        "    # OTSU threshold lines are added by me. \n",
        "    (thresh, im_bw) = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "    gray = cv2.threshold(gray, thresh, 255, cv2.THRESH_BINARY)[1]\n",
        "\n",
        "    crop_rows = gray[~np.all(gray == pixel_value, axis=1), :]\n",
        "    cropped_image = crop_rows[:, ~np.all(crop_rows == pixel_value, axis=0)]\n",
        "    # cv2_imshow(cropped_image)\n",
        "    # print(cropped_image.shape)\n",
        "    return cropped_image\n",
        "\n",
        "# STEP 2 (INPUT FIRST STEP)\n",
        "\n",
        "# gray = cv2.imread('/content/0_0.jpg', cv2.IMREAD_GRAYSCALE)\n",
        "# crop_image = crop_image_remove_white(gray)\n",
        "\n"
      ],
      "metadata": {
        "id": "_mFUOvTD2Zlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def overlay_image_centre(img):\n",
        "  # grayscale image \n",
        "  h, w = img.shape\n",
        "  # print(h,w)\n",
        "\n",
        "  square_side = max(h,w)+10\n",
        "\n",
        "  # load background image as white\n",
        "  back = np.full((square_side,square_side),255,np.uint8)\n",
        "  hh, ww = back.shape\n",
        "  # print(hh,ww)\n",
        "\n",
        "  # compute xoff and yoff for placement of upper left corner of resized image   \n",
        "  yoff = round((hh-h)/2)\n",
        "  xoff = round((ww-w)/2)\n",
        "  # print(yoff,xoff)\n",
        "\n",
        "  # use numpy indexing to place the resized image in the center of background image\n",
        "  result = back.copy()\n",
        "  result[yoff:yoff+h, xoff:xoff+w] = img\n",
        "\n",
        "  # view result\n",
        "  # cv2_imshow(result)\n",
        "  return result \n",
        "\n",
        "# t = overlay_image_centre(crop_image)\n",
        "\n",
        "# print(type(t))"
      ],
      "metadata": {
        "id": "lQV86RU2T0RW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dilation \n",
        "\n",
        "def dilation_resize(img):\n",
        "  img = cv2.resize(img,(100,100)) # resize for inputs to be of same size\n",
        "  \n",
        "  # refer - https://docs.opencv.org/3.4/d9/d61/tutorial_py_morphological_ops.html#:~:text=kernel%20%3D%20np.ones((5%2C5)%2Cnp.uint8) \n",
        "  # kernel = np.full((5,5),255,np.uint8) # white background \n",
        "  kernel = np.ones((5,5),np.uint8) \n",
        "\n",
        "  img = (255-img) #invert threshold(b/w) image \n",
        "\n",
        "  # erosion = cv2.erode(img,kernel,iterations = 1)\n",
        "\n",
        "  dilation = cv2.dilate(img,kernel,iterations = 1)\n",
        "\n",
        "  # opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "  # closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "  img = (255-dilation) #invert threshold(b/w) image \n",
        "  img = cv2.resize(img,(28,28))\n",
        "\n",
        "  return img\n",
        "  \n",
        "# img = cv2.imread('/content/0_0.jpg')\n",
        "# cv2_imshow(dilation_resize(img))"
      ],
      "metadata": {
        "id": "fQjwUwJv6vWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "reading dataset files "
      ],
      "metadata": {
        "id": "tnwCr1yMhp7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.display import display_markdown\n",
        "#create training data\n",
        "training_data = []\n",
        "CATEGORIES = []\n",
        "images= []\n",
        "images_path = []\n",
        "DATADIR = '/content/dataset'\n",
        "def count_least_number_images_in_class_training_data():\n",
        "    count = 10000 # count least images among any of the folder  \n",
        "    for category in CATEGORIES:  # do \n",
        "        index = 0\n",
        "        path = os.path.join(DATADIR,str(category))  # create path to classes\n",
        "        class_num = CATEGORIES.index(category)  # get the classification \n",
        "        print(path)\n",
        "        for img in tqdm(os.listdir(path)):  # iterate over each image \n",
        "            try:\n",
        "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
        "                if img_array.shape == (180,364) or img_array.shape==(364,180): # added 01-02-2022\n",
        "                  os.remove(os.path.join(path,img))\n",
        "                  continue\n",
        "                index+=1\n",
        "            except Exception as e:  # in the interest in keeping the output clean...\n",
        "                pass\n",
        "        if count>index:\n",
        "          count=index \n",
        "    print('---------------------')\n",
        "    return count\n",
        "\n",
        "exception = 0\n",
        "def create_training_data():\n",
        "    count = count_least_number_images_in_class_training_data()\n",
        "    fill = len(str(count))+1 # for giving names to images\n",
        "    \n",
        "    for category in CATEGORIES:  # do \n",
        "        index = 0\n",
        "        path = os.path.join(DATADIR,str(category))  # create path to classes\n",
        "        class_num = CATEGORIES.index(category)  # get the classification  \n",
        "\n",
        "        for img in tqdm(os.listdir(path)):  # iterate over each image \n",
        "            try:\n",
        "                \n",
        "\n",
        "                # comment following if statement for unbalanced classes\n",
        "                if (index+1)>count:\n",
        "                  #remove that image \n",
        "                  os.remove(os.path.join(path,img))\n",
        "                  continue # for balanced classes\n",
        "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
        "                # TODO - first cropped image and the preprocess and see result. Current code resizes image at last.\n",
        "                \n",
        "                # added 01-02-2022\n",
        "                img_array = cv2.resize(img_array,(100,100))\n",
        "\n",
        "                # STEP 1 and 2\n",
        "                cropped = crop_image_remove_white(img_array)\n",
        "                \n",
        "                # STEP 3\n",
        "                overlay = overlay_image_centre(cropped)\n",
        "                \n",
        "                # STEP 4 \n",
        "                dilation = dilation_resize(overlay)\n",
        "               \n",
        "                # for debug \n",
        "                # images.append([img_array,cropped,overlay,dilation])\n",
        "                # ipyplot.plot_images([img_array,cropped,overlay,dilation],['original','cropped_threshold','overlay','dilation'] ,max_images=10, img_width=100)\n",
        "              \n",
        "\n",
        "                # Reference - https://stackoverflow.com/questions/18805348/how-rename-the-images-in-folder/47105286#:~:text=import%20os%0Afor%20dirname%20in%20os.listdir(%22.%22)%3A%0A%20%20%20%20if%20os.path.isdir(dirname)%3A%0A%20%20%20%20%20%20%20%20for%20i%2C%20filename%20in%20enumerate(os.listdir(dirname))%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20os.rename(dirname%20%2B%20%22/%22%20%2B%20filename%2C%20dirname%20%2B%20%22/%22%20%2B%20str(i)%20%2B%20%22.bmp%22)\n",
        "                os.rename(os.path.join(path,img),os.path.join(path,str(category)+\"_\"+str(index).zfill(fill)+\".jpg\"))\n",
        "                cv2.imwrite(os.path.join(path,str(category)+\"_\"+str(index).zfill(fill)+\".jpg\"),dilation) # overwrite image \n",
        "                index+=1\n",
        "                \n",
        "                images_path.append(os.path.join(path,str(category)+\"_\"+str(index).zfill(fill)+\".jpg\"))\n",
        "                # print(path)     \n",
        "                  \n",
        "                training_data.append([dilation, class_num])  # add this to our training_data\n",
        "            except Exception as e:  # in the interest in keeping the output clean...\n",
        "                global exception\n",
        "                exception+=1\n",
        "                pass\n",
        "            #except OSError as e:\n",
        "            #    print(\"OSErrroBad img most likely\", e, os.path.join(path,img))\n",
        "            #except Exception as e:\n",
        "            #    print(\"general exception\", e, os.path.join(path,img))\n",
        "\n",
        "            # break # for one iteration break/ debug\n",
        "        print(\"\\nImages in class\",category,\"are\",index)\n",
        "        # break # for debug \n",
        "\n",
        "print('exceptions occurred :',exception)\n",
        "create_training_data() #don't use argument aspect_ratio (To use, load function - https://colab.research.google.com/drive/11gfaJEI9Q5D3YhocdW4fe8CK7dbp5uhJ?authuser=1#scrollTo=k1ZLDtYDTtcg&line=1&uniqifier=1 )\n",
        "print(\"\\n\",\"Length of training data \",len(training_data))\n",
        "# ipyplot.plot_class_representations(images_path, img_width=150,force_b64=True)\n"
      ],
      "metadata": {
        "id": "YNWx8yy7yD-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "download dataset in zip"
      ],
      "metadata": {
        "id": "w5JlZ5X9Xc_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/preprocessed_dataset.zip /content/dataset\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"/content/preprocessed_dataset.zip\")"
      ],
      "metadata": {
        "id": "rkZrmh-hhq4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "shuffle"
      ],
      "metadata": {
        "id": "G6vDv8S8XioA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.shuffle(training_data)\n",
        "\n",
        "# Our training_data is a list, meaning it's mutable, so it's now nicely shuffled. \n",
        "#We can confirm this by iterating over a few of the initial samples and printing out the class.\n",
        "for sample in training_data[:10]:\n",
        "    print(sample[1])"
      ],
      "metadata": {
        "id": "bIMaPuOLyeCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "convert to numpy"
      ],
      "metadata": {
        "id": "saZftMKZXlCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = [] #features\n",
        "y = [] #labels\n",
        "\n",
        "for features,label in training_data:\n",
        "    X.append(features)\n",
        "    y.append(label)\n",
        "\n",
        "print(type(X[0]),X[0].shape)\n",
        "# print(X[0].reshape(-1, IMG_SIZE, IMG_SIZE, 1)) # Gives error TODO \n",
        "# print(np.array(X).shape,np.array(X).reshape(-1, 28, 28, 1).shape,np.array(y).shape)\n",
        "\n",
        "# X = np.array(X).reshape(-1, 28, 28, 1)   \n",
        "X=np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(X.shape,y.shape)"
      ],
      "metadata": {
        "id": "7-739Dl6yjEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "plot images class wise"
      ],
      "metadata": {
        "id": "oS0m_uWVXpsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ipyplot.plot_class_representations(X,y, img_width=28,force_b64=True)\n",
        "ipyplot.plot_class_tabs(X, y, max_imgs_per_tab=20, img_width=50)"
      ],
      "metadata": {
        "id": "EkjDM9BsRvDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "export to pickle file"
      ],
      "metadata": {
        "id": "BhsQ3JKbXsmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save data \n",
        "\n",
        "import pickle\n",
        "dataset = [\"train\",\"test\",\"validate\"]\n",
        "name = dataset[1] # select name for data files \n",
        "pickle_out = open(\"x_\"+name+\".pickle\",\"wb\")\n",
        "pickle.dump(X, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out = open(\"y_\"+name+\".pickle\",\"wb\")\n",
        "pickle.dump(y, pickle_out)\n",
        "pickle_out.close()\n",
        "files.download(\"x_\"+name+\".pickle\")\n",
        "files.download(\"y_\"+name+\".pickle\")"
      ],
      "metadata": {
        "id": "VFcAOfw3yqJc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e06fcf4a-2dc9-4614-9eda-1b43ef15e49d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_b45c3794-05c8-4bfa-a0ed-127f1ffaaa9a\", \"x_test.pickle\", 341201)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_678347a4-e626-4d59-9c16-5a257d3cc460\", \"y_test.pickle\", 3637)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}